# AI æ ¸å¿ƒåº“

## ä¸€ã€é¡¹ç›®ç”±æ¥

åœ¨**å·¥ä¸šæµç¨‹**ä¸­ï¼Œæ·±åº¦å­¦ä¹ åº”ç”¨è¿‡ç¨‹åŒ…æ‹¬ï¼š

1. TrainVal(é’ˆå¯¹ç‰¹å®šåœºæ™¯ï¼Œç‰¹å®šæ•°æ®é›†è®­ç»ƒä¸€ä¸ªæ¨¡å‹)
2. Eval(ä½¿ç”¨éªŒè¯/æµ‹è¯•é›†æµ‹è¯•ï¼Œå¾—åˆ°å·¥ä¸šä¸Šçš„æ€§èƒ½æŒ‡æ ‡)
3. Demo(å°†æ¨¡å‹åšä¸ªdemoç»™å®¢æˆ·å±•ç¤º)
4. Export(å°†æ¨¡å‹è½¬æˆå…¶ä»–æ ¼å¼)
5. Deploy(å°†æ¨¡å‹éƒ¨ç½²åˆ°å…·ä½“çš„è®¾å¤‡ä¸Šï¼Œå¹¶æƒè¡¡é€Ÿåº¦ä¸å‡†ç¡®ç‡)
6. APP(å°†æ•´ä¸ªå·¥ä¸šæµç¨‹å°è£…æˆå¸¦ç•Œé¢çš„APP)

åœ¨**æ·±åº¦å­¦ä¹ è®­ç»ƒ**ä¸­ï¼Œè®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬ä»¥ä¸‹ç»„ä»¶ï¼š

- dataloaders(æ•°æ®åŠ è½½)
- models(æ¨¡å‹ï¼šåˆ†ç±»ã€åˆ†å‰²ã€æ£€æµ‹ã€å¼‚å¸¸æ£€æµ‹ç­‰[Task](https://paperswithcode.com/sota))
- losses(æŸå¤±å‡½æ•°)
- optims(ä¼˜åŒ–å™¨)
- schedulers(å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥)
- evaluator(è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ€§èƒ½è¯„ä»·)
- trainers(è®­ç»ƒè¿‡ç¨‹, å°†ä¸Šè¿°ç»„ä»¶è”ç³»èµ·æ¥, å¹¶ä¸”åŒ…å«ä¸€äº›è°ƒä¼˜trick)
    - resume
    - fune turning
    - æ—¥å¿—ç›‘æ§(è®­ç»ƒè¿‡ç¨‹æ—¥å¿—è¾“å‡ºï¼Œtensorboardï¼Œ...)
    - æƒé‡è¾“å‡º
    - multigpus(æ˜¯å¦ä½¿ç”¨å¤šGPUå½¢å¼è®­ç»ƒ)
    - mixedprecisions(æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è¿›è¡Œè®­ç»ƒ)
    - ......

ç›®å‰ï¼Œæˆ‘æ‰€é‡åˆ°çš„æ·±åº¦å­¦ä¹ é¡¹ç›®åŸºæœ¬éƒ½èƒ½ç”¨è¿™ä¸¤ä¸ªç»´åº¦æ¦‚æ‹¬ï¼Œä¸ºäº†æ–¹ä¾¿ä»¥åä½¿ç”¨ï¼Œåœ¨æ­¤å°†ä¸¤ä¸ªç»´åº¦æ•´ç†æˆè¿™ä¸ªé¡¹ç›®.

## äºŒã€é¡¹ç›®ç»“æ„
### 1. ç›®å½•ä»‹ç»
```shell
|-- configs # åˆ†ç±»ã€åˆ†å‰²ã€ç›®æ ‡æ£€æµ‹ã€å¼‚å¸¸æ£€æµ‹é…ç½®æ–‡ä»¶
|   |-- SemanticSegmentation
|   |-- ObejctDetection
|   |-- AnomalyDetection
|   `-- ImageClassification
|-- custom_modules  # è‡ªå®šä¹‰ç»„ä»¶
|   `-- __init__.py
|-- dao   # æ ¸å¿ƒåº“
|   |-- __init__.py
|   |-- dataloaders # æ•°æ®é›†ã€æ•°æ®åŠ è½½å™¨ã€æ•°æ®å¢å¼ºç­‰
|   |-- evaluators  # éªŒè¯å™¨
|   |-- losses      # æŸå¤±å‡½æ•°
|   |-- models      # æ¨¡å‹
|   |   |-- ImageClassification   # åˆ†ç±»
|   |   |-- ObejctDetection       # ç›®æ ‡æ£€æµ‹
|   |   |-- SemanticSegmentation  # åˆ†å‰²
|   |   |-- anomaly               # å¼‚å¸¸æ£€æµ‹
|   |   `-- backbone              # ä¸»å¹²ç½‘ç»œ
|   |-- optimizers  # ä¼˜åŒ–å™¨
|   |-- schedulers  # å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥
|   |-- trainers    # è®­ç»ƒå™¨
|   |-- register.py # æ³¨å†Œ, daoä¸­æ‰€æœ‰ç»„ä»¶éƒ½æ³¨å†Œåœ¨è¿™é‡Œ
|   `-- utils       # å·¥å…·åº“
|-- main.py         # å¯åŠ¨æ–‡ä»¶
|-- notes           # ç¬”è®°
|   |-- SemanticSegmentation
|   |-- ObejctDetection
|   |-- AnomalyDetection
|   `-- ImageClassification
```
### 2. Trainæµç¨‹
```shell
|- trainer
|	|- before_train(trainä¹‹å‰çš„æ“ä½œï¼Œeg. dataloader,model,optim,... setting)
|	|	|- 1.logger settingï¼šæ—¥å¿—è·¯å¾„ï¼Œtensorboardæ—¥å¿—è·¯å¾„ï¼Œæ—¥å¿—é‡å®šå‘ç­‰
|	|	|- 2.model settingï¼šè·å–æ¨¡å‹
|	|	|- 3.optimizer settingï¼šè·å–ä¼˜åŒ–å™¨ï¼Œä¸åŒæƒé‡å±‚ï¼Œä¼˜åŒ–å™¨å‚æ•°ä¸åŒçš„è®¾ç½®
|	|	|- 4.resume settingï¼šresumeï¼Œfune turningç­‰è®¾ç½®
|	|	|- 5.dataloader settingï¼šæ•°æ®é›†datasetå®šä¹‰-->Transformer(æ•°æ®å¢å¼ºï¼‰-->Dataloaderï¼ˆæ•°æ®åŠ è½½)--> ...
|	|   |- 6.loss setting: æŸå¤±å‡½æ•°é€‰æ‹©ï¼Œæœ‰çš„å®éªŒå¯ä»¥ç•¥æ‰ï¼Œå› ä¸ºåœ¨modelä¸­å®šä¹‰äº†
|	|   |- 7.scheduler settingï¼šå­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥é€‰æ‹©
|	|   |- 8.other setting: è¡¥å……2model settingï¼ŒEMAï¼ŒDDPæ¨¡å‹ç­‰è®¾ç½®
|	|   |- 9.evaluator settingï¼šéªŒè¯å™¨è®¾ç½®ï¼ŒåŒ…æ‹¬è¯»å–éªŒè¯é›†ï¼Œè®¡ç®—è¯„ä»·æŒ‡æ ‡ç­‰
|	|- train_in_epoch(è®­ç»ƒä¸€ä¸ªepochçš„æ“ä½œ)
|	|	|- before_epoch(ä¸€ä¸ªepochä¹‹å‰çš„æ“ä½œ)
|	|	|	|- åˆ¤æ–­æ­¤æ¬¡epochä½¿ç”¨è¿›è¡Œé©¬èµ›å…‹å¢å¼ºï¼›
|	|	|	|- ä¿®æ”¹æ­¤æ¬¡epochçš„æŸå¤±å‡½æ•°ï¼›
|	|	|	|- ä¿®æ”¹æ­¤æ¬¡epochçš„æ—¥å¿—ä¿¡æ¯æ ¼å¼;
|	|	|	|- ...
|	|	|- train_in_iter(è®­ç»ƒä¸€æ¬¡iterçš„æ“ä½œï¼Œä¸€æ¬¡å®Œæ•´çš„forward&backwards)
|	|	|	|- before_iter(ä¸€æ¬¡iterä¹‹å‰çš„æ“ä½œ)
|	|	|	|	|- nothing todo
|	|	|	|- train_one_iter(ä¸€æ¬¡iterçš„æ“ä½œ)
|	|	|	|	|- 1.è®°å½•data timeå’Œiter time
|	|	|	|	|- 2.(é¢„)è¯»å–æ•°æ®
|	|	|	|	|- 3.forward
|	|	|	|	|- 4.è®¡ç®—loss
|	|	|	|	|- 5.backwards
|	|	|	|	|- 6.optimizer æ›´æ–°ç½‘ç»œæƒé‡
|	|	|	|	|- 7.æ˜¯å¦è¿›è¡ŒEMAæ“ä½œ
|	|	|	|	|- 8.lr_schedulerä¿®æ”¹å­¦ä¹ ç‡
|	|	|	|	|- 9.è®°å½•æ—¥å¿—ä¿¡æ¯(datatime,itertime,å„ç§loss,...)
|	|	|	|- after_iter(ä¸€æ¬¡iterä¹‹åçš„æ“ä½œ)
|	|	|	|	|- 1.æ‰“å°ä¸€ä¸ªiterçš„æ—¥å¿—ä¿¡æ¯(epoch,iter,losses,gpu mem,lr,eta,...)
|	|	|	|	|- 2.æ˜¯å¦è¿›è¡Œå›¾ç‰‡çš„resizeï¼Œå³å¤šå°ºåº¦è®­ç»ƒ
|	|	|- after_epoch(ä¸€ä¸ªepochä¹‹åçš„æ“ä½œ)
|	|	|	|- 1.ä¿å­˜æ¨¡å‹
|	|	|	|- 2.æ˜¯å¦è¿›è¡Œï¼Œevaluator
|	|- after_train(è®­ç»ƒä¹‹åçš„æ“ä½œ)
|	|	|- è¾“å‡ºæœ€ä¼˜çš„ç»“æœ
```

### 3. Eval/Demo/Exportæµç¨‹

Eval/Demo/Exportæ˜¯Trainä¸­çš„å­é›†ï¼Œæˆ–è€…è¿‡ç¨‹æ¯”è¾ƒç®€å•ï¼Œæ­¤å¤„ä¸å†èµ˜è¿°ï¼Œçœ‹ä»£ç å³å¯

## ä¸‰ã€ç¯å¢ƒæ­å»º

### 1. å®¹å™¨åˆ¶ä½œ

æœ¬é¡¹ç›®çš„å®éªŒç¯å¢ƒå…¨éƒ¨æ˜¯åœ¨Dockerä¸­å®Œæˆçš„ï¼Œdockeré•œåƒçš„åˆ¶ä½œè¿‡ç¨‹å¦‚ä¸‹

```
sudo docker pull nvcr.io/nvidia/pytorch:22.02-py3
sudo docker run -it -v /home/user/data:/root/temp nvcr.io/nvidia/pytorch:22.02-py3 bash

apt-get install net-tools
apt-get install inetutils-ping
apt install ssh
vim /etc/ssh/sshd_config
ä¿®æ”¹rootå¯ç™»å½•
æŠŠAIServer, AICore, setup, start.shæ–‡ä»¶æ”¾åˆ°/aiç›®å½•ä¸‹
ln -s /ai/data/AITorch/hub/ /root/.cache/torch/
ln -s /opt/conda/bin/python /usr/bin/python
ln -s /opt/conda/bin/pip /usr/bin/pip
pip install python-socketio eventlet nvgpu xlsxwriter # AIServer
pip install dotmap loguru albumentations torchcam timm torchsummary scikit-image xlsxwriter  # AICore
```

## å››ã€å¦‚ä½•ä½¿ç”¨

ä»¥ä¸‹åªä¸¾ä¾‹ï¼Œåˆ†åˆ«åˆ—å‡ºäº†åˆ†ç±»ã€åˆ†å‰²ã€ç›®æ ‡æ£€æµ‹ã€å¼‚å¸¸æ£€æµ‹ä¸­ä¸€ä¸ªæ¨¡å‹çš„trainã€evaluateã€demoã€exportè¿‡ç¨‹ã€‚

### 1. ImageClassification

```
1. trainval
# å•æœºå•å¡
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-sgdWarmupBiasBnWeight-clsDataloader-crossEntropyLoss-warmCosLr-clsEvaluator-gpus-trainval-linux.json

# å•æœºå¤šå¡
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 2 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-sgdWarmupBiasBnWeight-clsDataloader-crossEntropyLoss-warmCosLr-clsEvaluator-gpus-trainval-linux.json

# å¤šæœºå¤šå¡
# use master ip 10.1.130.111
CUDA_VISIBLE_DEVICES=0,1  NCCL_SOCKET_IFNAME=eth0 NCCL_IB_DISABLE=1 NCCL_DEBUG=INFO  python main.py  --dist-url 'tcp://10.1.130.111:803' --dist-backend 'nccl' --num_machines 2 --machine_rank 0 --devices 2 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-sgdWarmupBiasBnWeight-clsDataloader-crossEntropyLoss-warmCosLr-clsEvaluator-gpus-trainval-linux.json
CUDA_VISIBLE_DEVICES=0,1  NCCL_SOCKET_IFNAME=eth0 NCCL_IB_DISABLE=1 NCCL_DEBUG=INFO  python main.py  --dist-url 'tcp://10.1.130.111:803' --dist-backend 'nccl' --num_machines 2 --machine_rank 1 --devices 2 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-sgdWarmupBiasBnWeight-clsDataloader-crossEntropyLoss-warmCosLr-clsEvaluator-gpus-trainval-linux.json

# use docker ip 172.17.0.2
CUDA_VISIBLE_DEVICES=0,1  python main.py  --dist-url 'tcp://172.17.0.2:1234' --dist-backend 'nccl' --num_machines 2 --machine_rank 0 --devices 2 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-sgdWarmupBiasBnWeight-clsDataloader-crossEntropyLoss-warmCosLr-clsEvaluator-gpus-trainval-linux.json
CUDA_VISIBLE_DEVICES=0,1  python main.py  --dist-url 'tcp://172.17.0.2:1234' --dist-backend 'nccl' --num_machines 2 --machine_rank 1 --devices 2 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-sgdWarmupBiasBnWeight-clsDataloader-crossEntropyLoss-warmCosLr-clsEvaluator-gpus-trainval-linux.json

2. eval
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-ClsDataloader-ClsEvaluator-eval-linux.json

3. demo
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-demo-linux.json

4. export
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-export-linux.json

```

### 2. SemanticSegmentation

```
1. trainval
# å•æœºå•å¡
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/SemanticSegmentation/seg-UNet_resnet50-sgdWarmupBiasBnWeight-segDataset-crossEntropyLoss-warmCosLr-segEvaluator-gpus-trainval-linux.json

# å•æœºå¤šå¡
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 2 -c /ai/AICore/configs/SemanticSegmentation/seg-UNet_resnet50-sgdWarmupBiasBnWeight-segDataset-crossEntropyLoss-warmCosLr-segEvaluator-gpus-trainval-linux.json

# å¤šæœºå¤šå¡
# use master ip 10.1.130.111
CUDA_VISIBLE_DEVICES=0,1  NCCL_SOCKET_IFNAME=eth0 NCCL_IB_DISABLE=1 NCCL_DEBUG=INFO  python main.py  --dist-url 'tcp://10.1.130.111:803' --dist-backend 'nccl' --num_machines 2 --machine_rank 0 --devices 2 -c /ai/AICore/configs/SemanticSegmentation/seg-UNet_resnet50-sgdWarmupBiasBnWeight-segDataset-crossEntropyLoss-warmCosLr-segEvaluator-gpus-trainval-linux.json
CUDA_VISIBLE_DEVICES=0,1  NCCL_SOCKET_IFNAME=eth0 NCCL_IB_DISABLE=1 NCCL_DEBUG=INFO  python main.py  --dist-url 'tcp://10.1.130.111:803' --dist-backend 'nccl' --num_machines 2 --machine_rank 1 --devices 2 -c /ai/AICore/configs/SemanticSegmentation/seg-UNet_resnet50-sgdWarmupBiasBnWeight-segDataset-crossEntropyLoss-warmCosLr-segEvaluator-gpus-trainval-linux.json

# use docker ip 172.17.0.2
CUDA_VISIBLE_DEVICES=0,1  python main.py  --dist-url 'tcp://172.17.0.2:1234' --dist-backend 'nccl' --num_machines 2 --machine_rank 0 --devices 2 -c /ai/AICore/configs/SemanticSegmentation/seg-UNet_resnet50-sgdWarmupBiasBnWeight-segDataset-crossEntropyLoss-warmCosLr-segEvaluator-gpus-trainval-linux.json
CUDA_VISIBLE_DEVICES=0,1  python main.py  --dist-url 'tcp://172.17.0.2:1234' --dist-backend 'nccl' --num_machines 2 --machine_rank 1 --devices 2 -c /ai/AICore/configs/SemanticSegmentation/seg-UNet_resnet50-sgdWarmupBiasBnWeight-segDataset-crossEntropyLoss-warmCosLr-segEvaluator-gpus-trainval-linux.json

2. eval
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/SemanticSegmentation/seg-UNet_resnet50-segDataset-segEvaluator-eval-linux.json

3. demo
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/SemanticSegmentation/seg-UNet_resnet50-demo-linux.json

4. export
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/SemanticSegmentation/seg-UNet_resnet50-export-linux.json

```

### 3. ObjectDetection

TODO

```
1. trainval
# å•æœºå•å¡
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-sgdWarmupBiasBnWeight-clsDataloader-crossEntropyLoss-warmCosLr-clsEvaluator-gpus-trainval-linux.json

# å•æœºå¤šå¡
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 2 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-sgdWarmupBiasBnWeight-clsDataloader-crossEntropyLoss-warmCosLr-clsEvaluator-gpus-trainval-linux.json

# å¤šæœºå¤šå¡
# use master ip 10.1.130.111
CUDA_VISIBLE_DEVICES=0,1  NCCL_SOCKET_IFNAME=eth0 NCCL_IB_DISABLE=1 NCCL_DEBUG=INFO  python main.py  --dist-url 'tcp://10.1.130.111:803' --dist-backend 'nccl' --num_machines 2 --machine_rank 0 --devices 2 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-sgdWarmupBiasBnWeight-clsDataloader-crossEntropyLoss-warmCosLr-clsEvaluator-gpus-trainval-linux.json
CUDA_VISIBLE_DEVICES=0,1  NCCL_SOCKET_IFNAME=eth0 NCCL_IB_DISABLE=1 NCCL_DEBUG=INFO  python main.py  --dist-url 'tcp://10.1.130.111:803' --dist-backend 'nccl' --num_machines 2 --machine_rank 1 --devices 2 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-sgdWarmupBiasBnWeight-clsDataloader-crossEntropyLoss-warmCosLr-clsEvaluator-gpus-trainval-linux.json

# use docker ip 172.17.0.2
CUDA_VISIBLE_DEVICES=0,1  python main.py  --dist-url 'tcp://172.17.0.2:1234' --dist-backend 'nccl' --num_machines 2 --machine_rank 0 --devices 2 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-sgdWarmupBiasBnWeight-clsDataloader-crossEntropyLoss-warmCosLr-clsEvaluator-gpus-trainval-linux.json
CUDA_VISIBLE_DEVICES=0,1  python main.py  --dist-url 'tcp://172.17.0.2:1234' --dist-backend 'nccl' --num_machines 2 --machine_rank 1 --devices 2 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-sgdWarmupBiasBnWeight-clsDataloader-crossEntropyLoss-warmCosLr-clsEvaluator-gpus-trainval-linux.json

2. eval
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-ClsDataloader-ClsEvaluator-eval-linux.json

3. demo
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-demo-linux.json

4. export
CUDA_VISIBLE_DEVICES=0,1  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/ImageClassification/cls-efficientnetb0-export-linux.json

```

### 4. AnomalyDetection

```
1. trainval
# å•æœºå•å¡
CUDA_VISIBLE_DEVICES=0  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/AnomalyDetection/anomaly-PaDiM2_L-MVTecDataset-trainval-linux.json

2. demo
CUDA_VISIBLE_DEVICES=0  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/AnomalyDetection/anomaly-PaDiM2_L-MVTecDataset-demo-linux.json

4. export
CUDA_VISIBLE_DEVICES=0  python main.py --num_machines 1 --machine_rank 0 --devices 1 -c /ai/AICore/configs/AnomalyDetection/anomaly-PaDiM2_L-MVTecDataset-export-linux.json

```



## äº”ã€æ”¯æŒæ¨¡å‹

### Models

#### 1. BackBone:[notes](notes/BackBone/README.md)
- timm:[code ref](https://github.com/AICoreRef/pytorch-image-models)
#### 2. ImageClassification:[notes](notes/ImageClassification/README.md)
åˆ†ç±»å…¨éƒ¨åœ¨timmåŸºç¡€ä¸Šä¿®æ”¹çš„, å› æ­¤[code ref](https://github.com/AICoreRef/pytorch-image-models)åŒä¸Š
- efficientnetb0
- efficientnetb1
- resnet18
- resnet34
- resnet50
- resnet101

#### æ•ˆæœå¯¹æ¯”

| æ¨¡å‹ | å¤–è§‚æ•°æ®PZ-éªŒè¯é›†top1 | å¤–è§‚æ•°æ®PZ-æµ‹è¯•é›†top1 | æƒé‡ |
| ---- | --------------------- | --------------------- | ---- |
|      |                       |                       |      |

#### 3. SemanticSegmentation:[notes](notes/SemanticSegmentation/README.md)
- Unet:[code ref](https://github.com/AICoreRef/segmentation_models.pytorch)
- Unet++:[code ref](https://github.com/AICoreRef/segmentation_models.pytorch)
- PSPNet:[code ref](https://github.com/AICoreRef/segmentation_models.pytorch)
- PSPNet2:[code ref](https://github.com/AICoreRef/pytorch-segmentation)
- DeepLabv3:[code ref](https://github.com/AICoreRef/segmentation_models.pytorch)
- DeepLabv3Plus:[code ref](https://github.com/AICoreRef/segmentation_models.pytorch)
- DeepLabv3Plus2:[code ref](https://github.com/AICoreRef/pytorch-segmentation)

##### æ•ˆæœå¯¹æ¯”

æ³¨æ„ï¼šä»¥ä¸‹å®éªŒå‡æ˜¯è·‘é€šå³å¯ï¼Œå‡æœªè°ƒä¼˜ï¼Œepochä¸º80.

| æ¨¡å‹           | ä¸»å¹²ç½‘ç»œ | PascalVoc-éªŒè¯é›†mIoU | PascalVoc -æµ‹è¯•é›†mIoU | æƒé‡ |
| -------------- | -------- | -------------------- | --------------------- | ---- |
| UNet           | resnet50 | 0.69                 | æœªæµ‹                  |      |
| UNet++         | resnet50 | 0.70                 | æœªæµ‹                  |      |
| PSPNet         | resnet50 | 0.72                 | æœªæµ‹                  |      |
| PSPNet2        | resnet50 | 0.76                 | æœªæµ‹                  |      |
| DeepLabV3      | resnet50 | 0.76                 | æœªæµ‹                  |      |
| DeepLabV3Plus  | resnet50 | 0.76                 | æœªæµ‹                  |      |
| DeepLabV3Plus2 | resnet50 | 0.75                 | æœªæµ‹                  |      |

#### 4. ObjectDetection:[notes](notes/ObjectDetection/README.md)

- YOLOX [code ref](https://github.com/Megvii-BaseDetection/YOLOX)

#### 5. AnomalyDetection:[notes](notes/AnomalyDetection/README.md)
- PaDim [code ref](https://github.com/AICoreRef/PaDiM-Anomaly-Detection-Localization-master) 
- PaDiM2 [code ref](https://github.com/AICoreRef/ind_knn_ad)

### Loss



## å…­ã€ç»„ä»¶è¯´æ˜

æ•´ä¸ªé¡¹ç›®æ˜¯ç”±trainer(train,eval,demo,export), dataloader, dataset,model,optimizer,loss,scheduler,evaluatorç»„ä»¶ç»„æˆã€‚å…¶ä¸­ï¼Œtrainerè´Ÿè´£å°†å…¶ä»–ç»„ä»¶æ‹¼æ¥èµ·æ¥ï¼Œæ¥ä¸‹æ¥ä¼šè¯´æ˜ä¸€äº›ç»„ä»¶ï¼Œä½†æ˜¯ä¸æ˜¯æ¯ä¸ªéƒ½è¯´ä¸‹ï¼Œè¯¦ç»†è¯·çœ‹ä»£ç ã€‚

### åˆ†å¸ƒå¼ç»„ä»¶

- PytorchåŸç”Ÿåˆ†å¸ƒå¼
  - DDPåŸç†1: https://zhuanlan.zhihu.com/p/76638962 
  - DDPåŸç†2: https://zhuanlan.zhihu.com/p/343951042
  - DDPéšæœºç§å­: https://bbs.cvmart.net/articles/5491

### æ•°æ®é›†æ ¼å¼

##### **Classification**

```
åˆ†ç±»æ•°æ®é›†

        data_dir:str  æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ–‡ä»¶å¤¹è¦æ±‚æ˜¯
            |-dataset
                |- ç±»åˆ«1
                    |-å›¾ç‰‡
                |- ç±»åˆ«2
                |- ......
                |- train.txt
                |- val.txt
                |- test.txt
                |- labels.txt

        image_set:str "train.txt", "val.txt" or "test.txt"
        in_channels:int  è¾“å…¥å›¾ç‰‡çš„é€šé“æ•°ï¼Œç›®å‰åªæ”¯æŒ1å’Œ3é€šé“
        input_size:tuple è¾“å…¥å›¾ç‰‡çš„HW
        preproc:albumentations.Compose å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
        cache:bool æ˜¯å¦å¯¹å›¾ç‰‡è¿›è¡Œå†…å­˜ç¼“å­˜
        separator:str labels.txt, train.txt, val.txt, test.txt çš„åˆ†å‰²ç¬¦ï¼ˆnameä¸idï¼‰
        images_suffix:list[str] å¯æ¥å—çš„å›¾ç‰‡åç¼€
```

##### **Segmentation**

```
åˆ†å‰²æ•°æ®é›†

        data_dir:str  æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ–‡ä»¶å¤¹è¦æ±‚æ˜¯
            |-dataset
                |- images
                    |-å›¾ç‰‡
                |- masks
                    |-å›¾ç‰‡
                |- train.txt
                |- val.txt
                |- test.txt
                |- labels.txt

        image_set:str "train.txt or val.txt or test.txt"
        in_channels:int  è¾“å…¥å›¾ç‰‡çš„é€šé“æ•°ï¼Œç›®å‰åªæ”¯æŒ1å’Œ3é€šé“
        input_size:tuple è¾“å…¥å›¾ç‰‡çš„HW
        preproc:albumentations.Compose å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
        cache:bool æ˜¯å¦å¯¹å›¾ç‰‡è¿›è¡Œå†…å­˜ç¼“å­˜
        images_suffix:str å¯æ¥å—çš„å›¾ç‰‡åç¼€
        mask_suffix:str å¯æ¥å—çš„å›¾ç‰‡åç¼€
```

##### **MvTecå¼‚å¸¸æ£€æµ‹æ•°æ®é›†**

```
        å¼‚å¸¸æ£€æµ‹æ•°æ®é›†ï¼Œï¼ˆMVTecDatasetç±»å‹ï¼‰

        data_dir:str  æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ–‡ä»¶å¤¹è¦æ±‚æ˜¯
            ğŸ“‚datasets æ•°æ®é›†åç§°
              â”£ ğŸ“‚ ground_truth  testæµ‹è¯•æ–‡ä»¶å¤¹å¯¹åº”çš„mask
              â”ƒ     â”£ ğŸ“‚ defective_type_1    å¼‚å¸¸ç±»åˆ«1 maskï¼ˆ0ï¼Œ255ï¼‰
              â”ƒ     â”— ğŸ“‚ defective_type_2    å¼‚å¸¸ç±»åˆ«2 mask
              â”£ ğŸ“‚ test  æµ‹è¯•æ–‡ä»¶å¤¹
              â”ƒ     â”£ ğŸ“‚ defective_type_1    å¼‚å¸¸ç±»åˆ«1 å›¾ç‰‡
              â”ƒ     â”£ ğŸ“‚ defective_type_2    å¼‚å¸¸ç±»åˆ«2 å›¾ç‰‡
              â”ƒ     â”— ğŸ“‚ good
              â”— ğŸ“‚ train è®­ç»ƒæ–‡ä»¶å¤¹
              â”ƒ     â”— ğŸ“‚ good

        preproc:albumentations.Compose å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
        image_set:str "train.txt or val.txt or test.txt"ï¼› train.txtæ˜¯è®­ç»ƒï¼Œå…¶ä½™æ˜¯æµ‹è¯•
        in_channels:int  è¾“å…¥å›¾ç‰‡çš„é€šé“æ•°ï¼Œç›®å‰åªæ”¯æŒ1å’Œ3é€šé“
        cache:bool æ˜¯å¦å¯¹å›¾ç‰‡è¿›è¡Œå†…å­˜ç¼“å­˜
        image_suffix:str å¯æ¥å—çš„å›¾ç‰‡åç¼€
        mask_suffix:str å¯æ¥å—çš„å›¾ç‰‡åç¼€
```



## ä¸ƒã€éƒ¨ç½²è¯´æ˜

æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒå®Œæ¯•åéœ€è¦éƒ¨ç½²åœ¨åµŒå…¥å¼ã€ä¸»æœºã€æ‰‹æœºç­‰è®¾å¤‡ä¸Šï¼Œéƒ¨ç½²è¿‡ç¨‹è¯·å‚è€ƒæˆ‘çš„å¦ä¸€ä¸ªé¡¹ç›®[AIDeploy](https://github.com/FelixFu520/AIDeploy)



## å…«ã€Debug

#### 1. é—®é¢˜1ï¼š

**ONNXä¸æ”¯æŒadaptive_avg_pool2d**

```
# RuntimeError: Unsupported: ONNX export of operator adaptive_avg_pool2d,
# since output size is not factor of input size.
# Please feel free to request support or submit a pull request on PyTorch GitHub.
```

**è§£å†³æ–¹æ³•**

- **[æ›¿æ¢nn.AdaptiveAvg2d](https://heroinlin.github.io/2018/08/15/Pytorch/Pytorch_export_onnx/)**
- [å‚è€ƒ1](https://www.cnblogs.com/xiaosongshine/p/10750908.html)

