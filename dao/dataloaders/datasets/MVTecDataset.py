
# -*- coding: utf-8 -*-
# @Author:FelixFu
# @Date: 2021.12.17
# @GitHub:https://github.com/felixfu520
# @Copy From: https://github.com/xiahaifeng1995/PaDiM-Anomaly-Detection-Localization-master/blob/main/datasets/mvtec.py

import os
import numpy as np
from PIL import Image
from loguru import logger

import torch
from torch.utils.data import Dataset
from torchvision import transforms as T

from dao.register import Registers

CLASS_NAMES = ['bottle', 'cable', 'capsule', 'carpet', 'grid',
               'hazelnut', 'leather', 'metal_nut', 'pill', 'screw',
               'tile', 'toothbrush', 'transistor', 'wood', 'zipper',
               'light', 'light_D1', 'light_D2']


@Registers.datasets.register
class MVTecDataset(Dataset):
    def __init__(self,
                 data_dir=None,
                 image_set="",
                 in_channels=1,  # æ²¡ç”¨åˆ°
                 cache=False,
                 image_suffix=".bmp",
                 mask_suffix=".png",
                 resize=224,
                 cropsize=224,
                 mean=[0.335782, 0.335782, 0.335782],
                 std=[0.256730, 0.256730, 0.256730],
                 **kwargs
                 ):
        """
        å¼‚å¸¸æ£€æµ‹æ•°æ®é›†ï¼Œï¼ˆMVTecDatasetç±»åž‹ï¼‰

        data_dir:str  æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„ï¼Œæ–‡ä»¶å¤¹è¦æ±‚æ˜¯
            ðŸ“‚datasets æ•°æ®é›†åç§°
              â”£ ðŸ“‚ ground_truth  testæµ‹è¯•æ–‡ä»¶å¤¹å¯¹åº”çš„mask
              â”ƒ     â”£ ðŸ“‚ defective_type_1    å¼‚å¸¸ç±»åˆ«1 maskï¼ˆ0ï¼Œ255ï¼‰
              â”ƒ     â”— ðŸ“‚ defective_type_2    å¼‚å¸¸ç±»åˆ«2 mask
              â”£ ðŸ“‚ test  æµ‹è¯•æ–‡ä»¶å¤¹
              â”ƒ     â”£ ðŸ“‚ defective_type_1    å¼‚å¸¸ç±»åˆ«1 å›¾ç‰‡
              â”ƒ     â”£ ðŸ“‚ defective_type_2    å¼‚å¸¸ç±»åˆ«2 å›¾ç‰‡
              â”ƒ     â”— ðŸ“‚ good
              â”— ðŸ“‚ train è®­ç»ƒæ–‡ä»¶å¤¹
              â”ƒ     â”— ðŸ“‚ good

        preproc:albumentations.Compose å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†
        image_set:str "train.txt or val.txt or test.txt"ï¼› train.txtæ˜¯è®­ç»ƒï¼Œå…¶ä½™æ˜¯æµ‹è¯•
        in_channels:int  è¾“å…¥å›¾ç‰‡çš„é€šé“æ•°ï¼Œç›®å‰åªæ”¯æŒ1å’Œ3é€šé“
        cache:bool æ˜¯å¦å¯¹å›¾ç‰‡è¿›è¡Œå†…å­˜ç¼“å­˜
        image_suffix:str å¯æŽ¥å—çš„å›¾ç‰‡åŽç¼€
        mask_suffix:str å¯æŽ¥å—çš„å›¾ç‰‡åŽç¼€
        """
        # set attr
        self.root = data_dir    # æ•°æ®é›†è·¯å¾„
        self.is_train = True if image_set == "train.txt" else False  # æ˜¯å¦æ˜¯è®­ç»ƒ
        self.in_channels = in_channels  # è¾“å…¥å›¾ç‰‡é€šé“æ•°
        self.image_suffix = image_suffix    # å›¾ç‰‡åŽç¼€
        self.mask_suffix = mask_suffix      # maskåŽç¼€
        self.resize = resize
        self.cropsize = cropsize
        self.mean = mean
        self.std = std

        # å­˜å‚¨image-mask pair
        self.x, self.y, self.mask = self.load_dataset_folder()  # xå­˜æ”¾å›¾ç‰‡çš„è·¯å¾„ï¼›yæ ‡å¿—æ­¤å›¾ç‰‡æ˜¯å¦æ˜¯goodï¼Œgoodä¸º0ï¼Œéžgoodä¸º1ï¼›maskå­˜æ”¾maskå›¾ç‰‡è·¯å¾„ï¼Œgoodä¸ºç©ºï¼›

        if cache:
            logger.warning("MVTecDataset not supported cache !")

        # set transforms
        self.transform_x = T.Compose([T.Resize(self.resize, Image.ANTIALIAS),
                                      T.CenterCrop(self.cropsize),
                                      T.ToTensor(),
                                      T.Normalize(mean=self.mean,  # 0.485, 0.456, 0.406
                                                  std=self.std)])  # 0.229, 0.224, 0.225
        self.transform_mask = T.Compose([T.Resize(self.resize, Image.NEAREST),
                                         T.CenterCrop(self.cropsize),
                                         T.ToTensor()])

    def __getitem__(self, idx):
        x, y, mask = self.x[idx], self.y[idx], self.mask[idx]  # xå­˜æ”¾å›¾ç‰‡çš„è·¯å¾„ï¼Œyæ ‡å¿—æ­¤å›¾ç‰‡æ˜¯å¦æ˜¯goodï¼ˆ0ï¼‰ï¼Œmaskå­˜æ”¾maskå›¾ç‰‡è·¯å¾„

        image = Image.open(x).convert('RGB')
        image = self.transform_x(image)

        if y == 0:
            mask = torch.zeros([1, self.cropsize, self.cropsize])
        else:
            mask = Image.open(mask)
            mask = self.transform_mask(mask)

        return image, y, mask, x

    def load_dataset_folder(self):
        phase = 'train' if self.is_train else 'test'
        x, y, mask = [], [], []     # xå­˜æ”¾å›¾ç‰‡çš„è·¯å¾„ï¼Œyæ ‡å¿—æ­¤å›¾ç‰‡æ˜¯å¦æ˜¯goodï¼ˆ0ï¼‰ï¼Œmaskå­˜æ”¾maskå›¾ç‰‡è·¯å¾„

        # èŽ·å¾—datasetç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å¤¹ï¼Œå³trainã€testã€ground_truth
        img_dir = os.path.join(self.root, phase)    # è®­ç»ƒé›†æˆ–æµ‹è¯•é›†æ–‡ä»¶å¤¹
        gt_dir = os.path.join(self.root, 'ground_truth')    # çœŸå®žmaskæ–‡ä»¶å¤¹

        # å¦‚æžœæ˜¯trainï¼Œåˆ™åªæœ‰good
        # å¦‚æžœæ˜¯testï¼Œåˆ™æœ‰goodã€å…¶ä»–å¼‚å¸¸ç±»åˆ«
        img_types = sorted(os.listdir(img_dir))  # goodã€å…¶ä»–å¼‚å¸¸ç±»åˆ«
        for img_type in img_types:  # å¤„ç†æ¯ä¸ªå¼‚å¸¸ç±»åˆ«ï¼ˆåŒ…æ‹¬goodï¼‰ï¼Œtrainå’Œtestæƒ…å†µã€‚
            # load images
            img_type_dir = os.path.join(img_dir, img_type)
            if not os.path.isdir(img_type_dir):
                continue
            # éåŽ†å…¶ä¸­ä¸€ä¸ªç±»åˆ«ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
            img_fpath_list = sorted([os.path.join(img_type_dir, f)
                                     for f in os.listdir(img_type_dir)
                                     if f.endswith(self.image_suffix)])
            x.extend(img_fpath_list)

            # load gt labels
            if img_type == 'good':
                y.extend([0] * len(img_fpath_list))
                mask.extend([None] * len(img_fpath_list))
            else:
                y.extend([1] * len(img_fpath_list))
                gt_type_dir = os.path.join(gt_dir, img_type)
                img_fname_list = [os.path.splitext(os.path.basename(f))[0] for f in img_fpath_list]
                if self.root.split('/')[-1] in CLASS_NAMES:  # å¦‚æžœæ˜¯MVTecæ•°æ®é›†ï¼Œmaskæœ‰_mask.png
                    gt_fpath_list = [os.path.join(gt_type_dir, img_name + "_mask" + self.mask_suffix) for img_name in
                                     img_fname_list]
                else:   # å¦‚æžœæ˜¯è‡ªå®šä¹‰æ•°æ®ï¼Œåˆ™æ— _mask.png
                    gt_fpath_list = [os.path.join(gt_type_dir, img_name + self.mask_suffix) for img_name in
                                     img_fname_list]
                mask.extend(gt_fpath_list)

        assert len(x) == len(y), 'number of x and y should be same'

        return list(x), list(y), list(mask)

    def __len__(self):
        return len(self.x)

    def __repr__(self):
        fmt_str = "Dataset:" + self.__class__.__name__
        fmt_str += "; Length:{}".format(self.__len__())
        fmt_str += "; Data_dir:{}".format(self.root)
        return fmt_str


if __name__ == "__main__":
    from dao.dataloaders.augments import get_transformer
    from dotmap import DotMap
    dataset_c = {
        "type": "MVTecDataset",
        "kwargs": {
            "data_dir": "/ai/data/AIDatasets/AnomalyDetection/4AR6N-L546S-DQSM9-424ZM-N4DZ2/zipper",
            "image_set": "test.txt",
            "in_channels": 1,
            "cache": False,
            "image_suffix": ".png",
            "mask_suffix": ".png"
        },
        "transforms": {
            "kwargs": {
                "Resize": {"height": 224, "width": 224, "p": 1, "interpolation": 0},
                "Normalize": {"mean": 0, "std": 1, "p": 1}
            }
        }
    }
    dataset_c = DotMap(dataset_c)
    transformer = get_transformer(dataset_c.transforms.kwargs)
    dataset = MVTecDataset(preproc=transformer, **dataset_c.kwargs)

    for i in range(len(dataset)):
        img, mask, label, img_p = dataset.__getitem__(i)
        print("image path:{}-->mask unique:{}".format(img_p, np.unique(mask)))
